{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTmcFR2IwF+8KaNXffsTEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/MachineLearning/blob/master/7%20K-Nearest%20Neighbors/KNN_Algorithm_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors Algorithm and Implementation\n"
      ],
      "metadata": {
        "id": "kgPAtbjqn-Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm\n",
        "\n",
        "Suppose:\n",
        "\n",
        "> There are dataset $x^{(1)}, x^{(2)},...,x^{(n)}$, \n",
        "> and the labels $y^{(1)}, y^{(2)},...,y^{(n)}$\n",
        ">\n",
        "> there are $n$ data points in the dataset\n",
        ">\n",
        "> there is a new data point $x_{new}$\n",
        "\n",
        "<br>\n",
        "\n",
        "There are five steps for KNN\n",
        "\n",
        "1.$\\; $Select a $k$ as the number of neighbors.\n",
        "\n",
        "2.$\\; $Calculate the distances from the new data point $x_{new}$ to each data points $x^{(i)}$, where $i \\in [1,n]$\n",
        "\n",
        "> Euclidean Distance function, see below, is used for calculating the distance.\n",
        "> The calculated distance is an array of size $n$.\n",
        "```\n",
        "def _euclidean(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2, axis=1))\n",
        "distances = _euclidean(X, x_new)\n",
        "```\n",
        "\n",
        "3.$\\; $Sort the calculated distances in ascending order, and get top $k$ items from the sorted distances.\n",
        "\n",
        "> The distances are sorted from small to large.\n",
        ">\n",
        "> The $k$ items are the nearest neighbors.\n",
        ">\n",
        "> Get the indices of the $k$ nearest neighbors.\n",
        "```\n",
        "kneighbors = np.argsort(distances)[:k]\n",
        "```\n",
        "\n",
        "4.$\\; $Get the labels of the $k$ nearest neighbors by their indices.\n",
        "\n",
        ">```\n",
        "labels = self.y[kneighbors]\n",
        ">```\n",
        "\n",
        "5.$\\; $Assign the new data point to the class with the most items from the classes of the $k$ nearest neighbors.\n",
        "\n",
        "> For example, the labels of the $k$ nearest neighbors are [0, 0, 1, 2, 2, 2 2], then assign 2 to the new data point because 2 is the most items.\n",
        "```\n",
        "pred = scipy.stats.mode(labels)[0]\n",
        "```"
      ],
      "metadata": {
        "id": "tGZ0rIqtNYmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Euclidean Distance function**\n",
        "\n",
        "Euclidean Distance function is used to calculate the distances in Step 2.\n",
        "\n",
        "In $2$-dimensional space, there are two vectors: $v = (x_1, y_1)$ and $u = (x_2, y_2)$, \n",
        "\n",
        "The Euclidean distance between $v$ and $u$ is:\n",
        "\n",
        "$\\quad d(u,v) = \\parallel u-v \\parallel = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$\n",
        "\n",
        "<br>\n",
        "\n",
        "In $n$-dimensional space there are vectors: $v = (v_1, v_2, ... , v_n)$ and $u =(u_1, u_2, ..., u_n)$, \n",
        "\n",
        "The Euclidean distance between $v$ and $u$ is:\n",
        "\n",
        "$\\quad d(u,v) = \\parallel u-v \\parallel = \\sqrt{(u_1-v_1)^2+(u_2-v_2)^2+...+(u_n-v_n)^2}$\n",
        "\n",
        "```\n",
        "def _euclidean(a, b):\n",
        "    return np.sqrt(np.sum((a - b)**2, axis=1))\n",
        "```"
      ],
      "metadata": {
        "id": "I7PivZDnVALR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation from Scratch"
      ],
      "metadata": {
        "id": "rKtv-v457v0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn import model_selection\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "0mxjsmEJpLmS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k):\n",
        "        #Step 1: select k\n",
        "        self.k = k\n",
        "\n",
        "    def _euclidean(self, a, b):\n",
        "        return np.sqrt(np.sum((a - b)**2, axis=1))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = []\n",
        "        for x in X:\n",
        "            #Step 2: calculate distances \n",
        "            distances = self._euclidean(self.X, x)\n",
        "            #Step 3: sort distances\n",
        "            kneighbors = np.argsort(distances)[:k]\n",
        "            #Step 4: get labels of k nearest neighbors\n",
        "            labels = self.y[kneighbors]\n",
        "            #Step 5: assign the most labels to new data\n",
        "            pred.append( stats.mode(labels)[0] )\n",
        "        return np.array(pred).reshape(-1, )"
      ],
      "metadata": {
        "id": "jIeLPFRA7znl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "wkjxX-9MPFUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris= datasets.load_iris()\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "model_selection.train_test_split(iris.data, \n",
        "                                 iris.target, \n",
        "                                 train_size = .75, \n",
        "                                 random_state=0)\n",
        "k = 7\n",
        "knn = KNN(k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "a_score = metrics.accuracy_score(y_test, y_pred)\n",
        "c_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "c_report = metrics.classification_report(y_test, y_pred)\n",
        "print(\"Accuracy Score:\\n\", a_score)\n",
        "print(\"Confusion matrix:\\n\", c_matrix)\n",
        "print(\"Classification Report:\\n\", c_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdB2GlmA93kS",
        "outputId": "3eea51b8-39d8-4ed2-a187-ffca52a2563e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:\n",
            " 0.9736842105263158\n",
            "Confusion matrix:\n",
            " [[13  0  0]\n",
            " [ 0 15  1]\n",
            " [ 0  0  9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      0.94      0.97        16\n",
            "           2       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        38\n",
            "   macro avg       0.97      0.98      0.97        38\n",
            "weighted avg       0.98      0.97      0.97        38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits = datasets.load_digits()\n",
        "X2_train, X2_test, y2_train, y2_test = \\\n",
        "model_selection.train_test_split(digits.data, \n",
        "                                 digits.target, \n",
        "                                 train_size = .75, \n",
        "                                 random_state=0)\n",
        "k = 1\n",
        "knn2 = KNN(k)\n",
        "knn2.fit(X2_train, y2_train)\n",
        "y2_pred = knn2.predict(X2_test)\n",
        "a2_score = metrics.accuracy_score(y2_test, y2_pred)\n",
        "c2_matrix = metrics.confusion_matrix(y2_test, y2_pred)\n",
        "c2_report = metrics.classification_report(y2_test, y2_pred)\n",
        "print(\"Accuracy Score:\\n\", a2_score)\n",
        "print(\"Confusion matrix:\\n\", c2_matrix)\n",
        "print(\"Classification Report:\\n\", c2_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRjqAQyiCcKv",
        "outputId": "184763ca-d010-4c95-8f94-d39a3dd3a181"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:\n",
            " 0.9911111111111112\n",
            "Confusion matrix:\n",
            " [[37  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 43  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 43  1  0  0  0  0  0  0]\n",
            " [ 0  0  0 45  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 38  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 47  0  0  0  1]\n",
            " [ 0  0  0  0  0  0 52  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 48  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 48  0]\n",
            " [ 0  0  0  1  0  1  0  0  0 45]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        37\n",
            "           1       1.00      1.00      1.00        43\n",
            "           2       1.00      0.98      0.99        44\n",
            "           3       0.96      1.00      0.98        45\n",
            "           4       1.00      1.00      1.00        38\n",
            "           5       0.98      0.98      0.98        48\n",
            "           6       1.00      1.00      1.00        52\n",
            "           7       1.00      1.00      1.00        48\n",
            "           8       1.00      1.00      1.00        48\n",
            "           9       0.98      0.96      0.97        47\n",
            "\n",
            "    accuracy                           0.99       450\n",
            "   macro avg       0.99      0.99      0.99       450\n",
            "weighted avg       0.99      0.99      0.99       450\n",
            "\n"
          ]
        }
      ]
    }
  ]
}